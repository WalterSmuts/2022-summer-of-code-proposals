\input{common-prelude}

\LARGE{\textbf{Monado}} \\
\vspace{1em}
\Large{XR - Fish Tank} \\
\vspace{1em}
\normalsize\textbf{Walter Smuts} \\
\normalsize{smuts.walter@gmail.com} \\
\vspace{1em}
\normalsize{Mentor: Jakob Bornecrantz} \\
\vspace{1em}
\normalsize{Google Summer of Code} \\

\end{center}
\begin{normalsize}

\section{Project Description:}

This project is one taken from the list of ideas presented by the organization
itself. Therefore the following description is taken verbatim from the
organization's website:

\begin{quote}

The core OpenXR 1.0 specification supports stereo VR headsets and monoscopic
handheld displays like smartphones or tablets which are supposed to be used as a
“magic window” into a VR world or for AR purposes; for this purpose the device’s
orientation and position is tracked to provide users the ability to move the
“window” view by moving the display device. A further use of monoscopic displays
is the “fish tank” configuration with a fixed display like a TV and instead the
head position of the user is tracked, to render the content behind the magic
window from the right perspective. (Example:
\url{https://www.youtube.com/watch?v=Jd3-eiid-Uw}). For this project, the student
will add support in Monado for tracking a face, figure out the relation of the
face/eyes to the a monitor and calculate fov values. The focus of this is not
making creating production ready code that in 100\% of the cases, but the
integration of the code into Monado. The small test application hello\_xr will
need changes to add better support for mono-scopic fish tank views, like improving
the scene setup. Depending on progress, the student can modify one or all of
Godot, Blender and Unreal to support mono-scopic fish tank mode.

\end{quote}

My understanding of this description is that the major work will lie in enabling
the face tracking feature in the Monado XR runtime. There are two ways to expose
this face tracking information to the XR application. One way is to use an
existing XR form factor (HMD or magic window) and send dynamic FOV values to
achieve the fish tank effect. This has the advantage of not having to change the
OpenXR spec at all and could even enable existing applications to work out of the
box. This, however, slightly abuses the form factor and may lead to unnecessary
complexity/confusion/bugs in the future.

Another option is to expose a whole new form factor, the fishtank configuration,
to the application and send the head position information explicitly. This allows
for much more flexibility and could be regarded as the "proper" way of doing
things.  Unfortunately it does require changes to the OpenXR spec and won't work
with applications that does not support the fishtank configuration explicitly.

Since there are two avenues for investigation here I need to choose one. The
advantages of having support for existing applications and not needing to go
through the process of having to upstream OpenXR spec changes seems attractive.
For this reason I propose this project follows the path of least resistance and
the rest of this document assumes we're NOT adding new XR form factors and ARE
implementing the dynamic FOV option, although please have a look at the "Inclusive
Suggestion" section.

The hello\_xr sample application can be used to test the fish tank feature,
although it might require some changes. If time permits I would like to write a
pure POC Magic Window application using Rust and the OpenXR rust bindings.

My intuition tells me the user experience may not be great. Most consumer device
cameras have a low framerate and high latency and may result in a high end to end
processing latency. I would expect the head position estimate to lag behind the
ground truth, and therefore the image on the screen will lag. This could possibly
be fixed by applying signal processing techniques such as a kalman filter or
incorporating gyroscopic and accelerometer data in the head position estimator. If
time permits, I'd like to explore these optimizations as well.

\section{Timeline:}

\begin{table}[H]
\centering
\begin{minipage}[t]{.7\linewidth}
\rule{\linewidth}{1pt}
\ytl{Week 1 - 2}{Download, compile, explore Monado runtime code and example applications}
\ytl{Week 3 - 4}{Get POC working, no matter how hacky}
\ytl{Week 5 - 6}{Compile a set of reviewable/maintainable patches}
\ytl{Week 7 - 8}{Make experience improvements - i.e. kalman filter, low pass filter or performance improvements}
\ytl{Week 9 - 10}{Code review process and merge PRs}
\ytl{Week 11 - 12}{Buffer Time - Things always take longer than expected}
\bigskip
\rule{\linewidth}{1pt}%
\end{minipage}%
\end{table}

\vspace*{-0.5cm}
\section{Deliverables:}

There are some deliverables that are clear and very likely to be delivered. These
are listed below:

\begin{itemize}
\setlength\itemsep{-0.1em}
\item Basic implementation of head/face tracking feature for the Monado XR runtime.
\item Integration of this code into Monado, code-reviewed and merged.
\item A working fish tank POC using the hello\_xr application. If the
application does not work out of the box, changes will be made to the application
to get to a working POC.
\end{itemize}

\noindent
Then there are some deliverables that are less clear or are dependent on time
constraints:

\begin{itemize}
\setlength\itemsep{-0.1em}
\item Improved head tracking using signal processing techniques
\item Rust fish tank demo application
\item Support in Godot/Blender/Unreal Engine for mono-scopic displays
\end{itemize}

\vspace*{-0.5cm}
\section{Inclusive suggestion:}

There seems to be more than one applicant interested in the fish tank project.
Google's rules for GSOC does not allow for multiple applicants to work on the same
project. If there are two strong candidates this puts the selection committee in a
difficult position of having to discard one. If this is the case I have a
suggestion that may help depending on how strict Google is about slightly changing
project descriptions after the applicants have been accepted. Since I've outlined
two different approaches for implementing an XR fish tank effect it makes sense to
have two applicants work in parallel, each on a separate approach. This could be
described as two DISTINCT projects with a common goal. I believe there is little
overlap in the actual coding work yet lots of overlap in theory. The advantage of
this is that the applicants could support each other in the theory while still
having complete ownership of their own project. I'd be happy to work on either
avenue of implementing the fish tank effect if this suggestion is viable. In my
mind, both are worth doing.

\input{common-tail}
